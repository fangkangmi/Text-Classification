{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-06-02T12:18:23.368625Z",
     "iopub.status.busy": "2023-06-02T12:18:23.368196Z",
     "iopub.status.idle": "2023-06-02T12:18:26.531951Z",
     "shell.execute_reply": "2023-06-02T12:18:26.530663Z",
     "shell.execute_reply.started": "2023-06-02T12:18:23.368595Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T12:18:26.534883Z",
     "iopub.status.busy": "2023-06-02T12:18:26.534275Z",
     "iopub.status.idle": "2023-06-02T12:18:26.545368Z",
     "shell.execute_reply": "2023-06-02T12:18:26.544369Z",
     "shell.execute_reply.started": "2023-06-02T12:18:26.534849Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T12:18:26.547647Z",
     "iopub.status.busy": "2023-06-02T12:18:26.546596Z",
     "iopub.status.idle": "2023-06-02T12:18:32.672077Z",
     "shell.execute_reply": "2023-06-02T12:18:32.670923Z",
     "shell.execute_reply.started": "2023-06-02T12:18:26.547614Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(555957, 18)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21145/3115789634.py:1: DtypeWarning: Columns (5,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(\"consumer_complaints.csv\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_received</th>\n",
       "      <th>product</th>\n",
       "      <th>sub_product</th>\n",
       "      <th>issue</th>\n",
       "      <th>sub_issue</th>\n",
       "      <th>consumer_complaint_narrative</th>\n",
       "      <th>company_public_response</th>\n",
       "      <th>company</th>\n",
       "      <th>state</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>tags</th>\n",
       "      <th>consumer_consent_provided</th>\n",
       "      <th>submitted_via</th>\n",
       "      <th>date_sent_to_company</th>\n",
       "      <th>company_response_to_consumer</th>\n",
       "      <th>timely_response</th>\n",
       "      <th>consumer_disputed?</th>\n",
       "      <th>complaint_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>08/30/2013</td>\n",
       "      <td>Mortgage</td>\n",
       "      <td>Other mortgage</td>\n",
       "      <td>Loan modification,collection,foreclosure</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>U.S. Bancorp</td>\n",
       "      <td>CA</td>\n",
       "      <td>95993</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Referral</td>\n",
       "      <td>09/03/2013</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>511074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>08/30/2013</td>\n",
       "      <td>Mortgage</td>\n",
       "      <td>Other mortgage</td>\n",
       "      <td>Loan servicing, payments, escrow account</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wells Fargo &amp; Company</td>\n",
       "      <td>CA</td>\n",
       "      <td>91104</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Referral</td>\n",
       "      <td>09/03/2013</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>511080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>08/30/2013</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Incorrect information on credit report</td>\n",
       "      <td>Account status</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wells Fargo &amp; Company</td>\n",
       "      <td>NY</td>\n",
       "      <td>11764</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Postal mail</td>\n",
       "      <td>09/18/2013</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>510473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>08/30/2013</td>\n",
       "      <td>Student loan</td>\n",
       "      <td>Non-federal student loan</td>\n",
       "      <td>Repaying your loan</td>\n",
       "      <td>Repaying your loan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Navient Solutions, Inc.</td>\n",
       "      <td>MD</td>\n",
       "      <td>21402</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Email</td>\n",
       "      <td>08/30/2013</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>510326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>08/30/2013</td>\n",
       "      <td>Debt collection</td>\n",
       "      <td>Credit card</td>\n",
       "      <td>False statements or representation</td>\n",
       "      <td>Attempted to collect wrong amount</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Resurgent Capital Services L.P.</td>\n",
       "      <td>GA</td>\n",
       "      <td>30106</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Web</td>\n",
       "      <td>08/30/2013</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>511067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  date_received           product               sub_product  \\\n",
       "0    08/30/2013          Mortgage            Other mortgage   \n",
       "1    08/30/2013          Mortgage            Other mortgage   \n",
       "2    08/30/2013  Credit reporting                       NaN   \n",
       "3    08/30/2013      Student loan  Non-federal student loan   \n",
       "4    08/30/2013   Debt collection               Credit card   \n",
       "\n",
       "                                      issue  \\\n",
       "0  Loan modification,collection,foreclosure   \n",
       "1  Loan servicing, payments, escrow account   \n",
       "2    Incorrect information on credit report   \n",
       "3                        Repaying your loan   \n",
       "4        False statements or representation   \n",
       "\n",
       "                           sub_issue consumer_complaint_narrative  \\\n",
       "0                                NaN                          NaN   \n",
       "1                                NaN                          NaN   \n",
       "2                     Account status                          NaN   \n",
       "3                 Repaying your loan                          NaN   \n",
       "4  Attempted to collect wrong amount                          NaN   \n",
       "\n",
       "  company_public_response                          company state zipcode tags  \\\n",
       "0                     NaN                     U.S. Bancorp    CA   95993  NaN   \n",
       "1                     NaN            Wells Fargo & Company    CA   91104  NaN   \n",
       "2                     NaN            Wells Fargo & Company    NY   11764  NaN   \n",
       "3                     NaN          Navient Solutions, Inc.    MD   21402  NaN   \n",
       "4                     NaN  Resurgent Capital Services L.P.    GA   30106  NaN   \n",
       "\n",
       "  consumer_consent_provided submitted_via date_sent_to_company  \\\n",
       "0                       NaN      Referral           09/03/2013   \n",
       "1                       NaN      Referral           09/03/2013   \n",
       "2                       NaN   Postal mail           09/18/2013   \n",
       "3                       NaN         Email           08/30/2013   \n",
       "4                       NaN           Web           08/30/2013   \n",
       "\n",
       "  company_response_to_consumer timely_response consumer_disputed?  \\\n",
       "0      Closed with explanation             Yes                Yes   \n",
       "1      Closed with explanation             Yes                Yes   \n",
       "2      Closed with explanation             Yes                 No   \n",
       "3      Closed with explanation             Yes                Yes   \n",
       "4      Closed with explanation             Yes                Yes   \n",
       "\n",
       "   complaint_id  \n",
       "0        511074  \n",
       "1        511080  \n",
       "2        510473  \n",
       "3        510326  \n",
       "4        511067  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"consumer_complaints.csv\")\n",
    "\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T12:18:32.675215Z",
     "iopub.status.busy": "2023-06-02T12:18:32.674386Z",
     "iopub.status.idle": "2023-06-02T12:18:33.065326Z",
     "shell.execute_reply": "2023-06-02T12:18:33.064188Z",
     "shell.execute_reply.started": "2023-06-02T12:18:32.675183Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_received</th>\n",
       "      <th>product</th>\n",
       "      <th>sub_product</th>\n",
       "      <th>issue</th>\n",
       "      <th>sub_issue</th>\n",
       "      <th>consumer_complaint_narrative</th>\n",
       "      <th>company_public_response</th>\n",
       "      <th>company</th>\n",
       "      <th>state</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>tags</th>\n",
       "      <th>consumer_consent_provided</th>\n",
       "      <th>submitted_via</th>\n",
       "      <th>date_sent_to_company</th>\n",
       "      <th>company_response_to_consumer</th>\n",
       "      <th>timely_response</th>\n",
       "      <th>consumer_disputed?</th>\n",
       "      <th>complaint_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>190126</th>\n",
       "      <td>03/19/2015</td>\n",
       "      <td>Debt collection</td>\n",
       "      <td>Other (i.e. phone, health club, etc.)</td>\n",
       "      <td>Cont'd attempts collect debt not owed</td>\n",
       "      <td>Debt was paid</td>\n",
       "      <td>XXXX has claimed I owe them {$27.00} for XXXX ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Diversified Consultants, Inc.</td>\n",
       "      <td>NY</td>\n",
       "      <td>121XX</td>\n",
       "      <td>Older American</td>\n",
       "      <td>Consent provided</td>\n",
       "      <td>Web</td>\n",
       "      <td>03/19/2015</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>1290516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190135</th>\n",
       "      <td>03/19/2015</td>\n",
       "      <td>Consumer Loan</td>\n",
       "      <td>Vehicle loan</td>\n",
       "      <td>Managing the loan or lease</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Due to inconsistencies in the amount owed that...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M&amp;T Bank Corporation</td>\n",
       "      <td>VA</td>\n",
       "      <td>221XX</td>\n",
       "      <td>Servicemember</td>\n",
       "      <td>Consent provided</td>\n",
       "      <td>Web</td>\n",
       "      <td>03/19/2015</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>1290492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190155</th>\n",
       "      <td>03/19/2015</td>\n",
       "      <td>Mortgage</td>\n",
       "      <td>Conventional fixed mortgage</td>\n",
       "      <td>Loan modification,collection,foreclosure</td>\n",
       "      <td>NaN</td>\n",
       "      <td>In XX/XX/XXXX my wages that I earned at my job...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wells Fargo &amp; Company</td>\n",
       "      <td>CA</td>\n",
       "      <td>946XX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Consent provided</td>\n",
       "      <td>Web</td>\n",
       "      <td>03/19/2015</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1290524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190207</th>\n",
       "      <td>03/19/2015</td>\n",
       "      <td>Mortgage</td>\n",
       "      <td>Conventional fixed mortgage</td>\n",
       "      <td>Loan servicing, payments, escrow account</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I have an open and current mortgage with Chase...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JPMorgan Chase &amp; Co.</td>\n",
       "      <td>CA</td>\n",
       "      <td>900XX</td>\n",
       "      <td>Older American</td>\n",
       "      <td>Consent provided</td>\n",
       "      <td>Web</td>\n",
       "      <td>03/19/2015</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1290253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190208</th>\n",
       "      <td>03/19/2015</td>\n",
       "      <td>Mortgage</td>\n",
       "      <td>Conventional fixed mortgage</td>\n",
       "      <td>Credit decision / Underwriting</td>\n",
       "      <td>NaN</td>\n",
       "      <td>XXXX was submitted XX/XX/XXXX. At the time I s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rushmore Loan Management Services LLC</td>\n",
       "      <td>CA</td>\n",
       "      <td>956XX</td>\n",
       "      <td>Older American</td>\n",
       "      <td>Consent provided</td>\n",
       "      <td>Web</td>\n",
       "      <td>03/19/2015</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1292137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       date_received          product                            sub_product  \\\n",
       "190126    03/19/2015  Debt collection  Other (i.e. phone, health club, etc.)   \n",
       "190135    03/19/2015    Consumer Loan                           Vehicle loan   \n",
       "190155    03/19/2015         Mortgage            Conventional fixed mortgage   \n",
       "190207    03/19/2015         Mortgage            Conventional fixed mortgage   \n",
       "190208    03/19/2015         Mortgage            Conventional fixed mortgage   \n",
       "\n",
       "                                           issue      sub_issue  \\\n",
       "190126     Cont'd attempts collect debt not owed  Debt was paid   \n",
       "190135                Managing the loan or lease            NaN   \n",
       "190155  Loan modification,collection,foreclosure            NaN   \n",
       "190207  Loan servicing, payments, escrow account            NaN   \n",
       "190208            Credit decision / Underwriting            NaN   \n",
       "\n",
       "                             consumer_complaint_narrative  \\\n",
       "190126  XXXX has claimed I owe them {$27.00} for XXXX ...   \n",
       "190135  Due to inconsistencies in the amount owed that...   \n",
       "190155  In XX/XX/XXXX my wages that I earned at my job...   \n",
       "190207  I have an open and current mortgage with Chase...   \n",
       "190208  XXXX was submitted XX/XX/XXXX. At the time I s...   \n",
       "\n",
       "       company_public_response                                company state  \\\n",
       "190126                     NaN          Diversified Consultants, Inc.    NY   \n",
       "190135                     NaN                   M&T Bank Corporation    VA   \n",
       "190155                     NaN                  Wells Fargo & Company    CA   \n",
       "190207                     NaN                   JPMorgan Chase & Co.    CA   \n",
       "190208                     NaN  Rushmore Loan Management Services LLC    CA   \n",
       "\n",
       "       zipcode            tags consumer_consent_provided submitted_via  \\\n",
       "190126   121XX  Older American          Consent provided           Web   \n",
       "190135   221XX   Servicemember          Consent provided           Web   \n",
       "190155   946XX             NaN          Consent provided           Web   \n",
       "190207   900XX  Older American          Consent provided           Web   \n",
       "190208   956XX  Older American          Consent provided           Web   \n",
       "\n",
       "       date_sent_to_company company_response_to_consumer timely_response  \\\n",
       "190126           03/19/2015      Closed with explanation             Yes   \n",
       "190135           03/19/2015      Closed with explanation             Yes   \n",
       "190155           03/19/2015      Closed with explanation             Yes   \n",
       "190207           03/19/2015      Closed with explanation             Yes   \n",
       "190208           03/19/2015      Closed with explanation             Yes   \n",
       "\n",
       "       consumer_disputed?  complaint_id  \n",
       "190126                 No       1290516  \n",
       "190135                 No       1290492  \n",
       "190155                Yes       1290524  \n",
       "190207                Yes       1290253  \n",
       "190208                Yes       1292137  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dropna(subset=[\"consumer_complaint_narrative\", \"product\"], inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T12:18:39.118810Z",
     "iopub.status.busy": "2023-06-02T12:18:39.118399Z",
     "iopub.status.idle": "2023-06-02T12:18:41.400475Z",
     "shell.execute_reply": "2023-06-02T12:18:41.399413Z",
     "shell.execute_reply.started": "2023-06-02T12:18:39.118776Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17142, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>consumer_complaint_narrative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>190155</th>\n",
       "      <td>Mortgage</td>\n",
       "      <td>In XX/XX/XXXX my wages that I earned at my job...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190208</th>\n",
       "      <td>Mortgage</td>\n",
       "      <td>XXXX was submitted XX/XX/XXXX. At the time I s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190251</th>\n",
       "      <td>Mortgage</td>\n",
       "      <td>I spoke to XXXX of green tree representatives ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190263</th>\n",
       "      <td>Credit card</td>\n",
       "      <td>i opened XXXX Bank of America credit cards 15-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190264</th>\n",
       "      <td>Consumer Loan</td>\n",
       "      <td>I applied for a loan with XXXX XXXX and had pu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              product                       consumer_complaint_narrative\n",
       "190155       Mortgage  In XX/XX/XXXX my wages that I earned at my job...\n",
       "190208       Mortgage  XXXX was submitted XX/XX/XXXX. At the time I s...\n",
       "190251       Mortgage  I spoke to XXXX of green tree representatives ...\n",
       "190263    Credit card  i opened XXXX Bank of America credit cards 15-...\n",
       "190264  Consumer Loan  I applied for a loan with XXXX XXXX and had pu..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['word_count'] = data['consumer_complaint_narrative'].str.split().str.len()\n",
    "data = data[data['word_count'] >= 250][[\"product\", \"consumer_complaint_narrative\"]]\n",
    "\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T12:19:13.812462Z",
     "iopub.status.busy": "2023-06-02T12:19:13.812051Z",
     "iopub.status.idle": "2023-06-02T12:19:13.828723Z",
     "shell.execute_reply": "2023-06-02T12:19:13.827441Z",
     "shell.execute_reply.started": "2023-06-02T12:19:13.812428Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mortgage                   6042\n",
       "Debt collection            2832\n",
       "Credit card                2293\n",
       "Bank account or service    1930\n",
       "Credit reporting           1753\n",
       "Consumer Loan              1066\n",
       "Student loan                734\n",
       "Money transfers             201\n",
       "Prepaid card                160\n",
       "Payday loan                 100\n",
       "Other financial service      31\n",
       "Name: product, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"product\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T12:19:49.164609Z",
     "iopub.status.busy": "2023-06-02T12:19:49.164162Z",
     "iopub.status.idle": "2023-06-02T12:19:49.174085Z",
     "shell.execute_reply": "2023-06-02T12:19:49.172832Z",
     "shell.execute_reply.started": "2023-06-02T12:19:49.164576Z"
    }
   },
   "outputs": [],
   "source": [
    "data = data[~data[\"product\"].isin([\"Other financial service\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T12:19:51.029914Z",
     "iopub.status.busy": "2023-06-02T12:19:51.029521Z",
     "iopub.status.idle": "2023-06-02T12:19:51.043400Z",
     "shell.execute_reply": "2023-06-02T12:19:51.042223Z",
     "shell.execute_reply.started": "2023-06-02T12:19:51.029876Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num labels:  10\n"
     ]
    }
   ],
   "source": [
    "num_labels = len(data[\"product\"].unique())\n",
    "print(\"num labels: \", num_labels)\n",
    "genre2id = {genre: i for i, genre in enumerate(data[\"product\"].unique())}\n",
    "id2genre = {i: genre for i, genre in enumerate(data[\"product\"].unique())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T12:20:05.307485Z",
     "iopub.status.busy": "2023-06-02T12:20:05.306702Z",
     "iopub.status.idle": "2023-06-02T12:20:05.328772Z",
     "shell.execute_reply": "2023-06-02T12:20:05.327521Z",
     "shell.execute_reply.started": "2023-06-02T12:20:05.307449Z"
    }
   },
   "outputs": [],
   "source": [
    "data[\"genre_id\"] = data[\"product\"].apply(lambda a: genre2id[a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T12:23:50.807374Z",
     "iopub.status.busy": "2023-06-02T12:23:50.806966Z",
     "iopub.status.idle": "2023-06-02T12:23:50.815167Z",
     "shell.execute_reply": "2023-06-02T12:23:50.814106Z",
     "shell.execute_reply.started": "2023-06-02T12:23:50.807343Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub('[^a-zA-Z0-9\\.\\,\\?\\!]', ' ', str(text).lower()) # remove all except lowercase, uppercase, digits, punctuation\n",
    "    text = re.sub('\\[.*?\\]', '', text) # remove any text in square brackets\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text) # remove any links present \n",
    "    text = re.sub('\\n', ' ', text) # remove the next line character\n",
    "    text = re.sub('\\w*\\d\\w*', '', text) # remove the words contaitning numbers\n",
    "    text = re.sub('\\s+', ' ', text) # remove extra spaces\n",
    "    text = re.sub('x{2,}', '', text) # remove multiple x's\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T12:23:52.233668Z",
     "iopub.status.busy": "2023-06-02T12:23:52.233160Z",
     "iopub.status.idle": "2023-06-02T12:24:10.602965Z",
     "shell.execute_reply": "2023-06-02T12:24:10.601849Z",
     "shell.execute_reply.started": "2023-06-02T12:23:52.233633Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>consumer_complaint_narrative</th>\n",
       "      <th>genre_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>190155</th>\n",
       "      <td>Mortgage</td>\n",
       "      <td>in    my wages that i earned at my job decreas...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190208</th>\n",
       "      <td>Mortgage</td>\n",
       "      <td>was submitted   . at the time i submitted thi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190251</th>\n",
       "      <td>Mortgage</td>\n",
       "      <td>i spoke to  of green tree representatives on  ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190263</th>\n",
       "      <td>Credit card</td>\n",
       "      <td>i opened  bank of america credit cards years a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190264</th>\n",
       "      <td>Consumer Loan</td>\n",
       "      <td>i applied for a loan with   and had purchased ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              product                       consumer_complaint_narrative  \\\n",
       "190155       Mortgage  in    my wages that i earned at my job decreas...   \n",
       "190208       Mortgage   was submitted   . at the time i submitted thi...   \n",
       "190251       Mortgage  i spoke to  of green tree representatives on  ...   \n",
       "190263    Credit card  i opened  bank of america credit cards years a...   \n",
       "190264  Consumer Loan  i applied for a loan with   and had purchased ...   \n",
       "\n",
       "        genre_id  \n",
       "190155         0  \n",
       "190208         0  \n",
       "190251         0  \n",
       "190263         1  \n",
       "190264         2  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['consumer_complaint_narrative'] = data['consumer_complaint_narrative'].apply(clean_text)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T12:25:00.740287Z",
     "iopub.status.busy": "2023-06-02T12:25:00.739861Z",
     "iopub.status.idle": "2023-06-02T12:25:00.758650Z",
     "shell.execute_reply": "2023-06-02T12:25:00.757716Z",
     "shell.execute_reply.started": "2023-06-02T12:25:00.740254Z"
    }
   },
   "outputs": [],
   "source": [
    "mortgage = data[data[\"genre_id\"] == 0]\n",
    "credit_card = data[data[\"genre_id\"] == 1]\n",
    "consumer_loan = data[data[\"genre_id\"] == 2]\n",
    "debt_collection = data[data[\"genre_id\"] == 3]\n",
    "credit_reporting = data[data[\"genre_id\"] == 4]\n",
    "student_loan = data[data[\"genre_id\"] == 5]\n",
    "bank_account = data[data[\"genre_id\"] == 6]\n",
    "money_transfers = data[data[\"genre_id\"] == 7]\n",
    "payday_loan = data[data[\"genre_id\"] == 8]\n",
    "prepaid_card = data[data[\"genre_id\"] == 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T12:25:10.933485Z",
     "iopub.status.busy": "2023-06-02T12:25:10.933092Z",
     "iopub.status.idle": "2023-06-02T12:25:11.690449Z",
     "shell.execute_reply": "2023-06-02T12:25:11.689249Z",
     "shell.execute_reply.started": "2023-06-02T12:25:10.933442Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "mortgage_downsample = resample(mortgage,\n",
    "                              replace=False,\n",
    "                              n_samples=600,\n",
    "                              random_state=42)\n",
    "\n",
    "credit_card_downsample = resample(credit_card,\n",
    "                              replace=False,\n",
    "                              n_samples=600,\n",
    "                              random_state=42)\n",
    "\n",
    "consumer_loan_downsample = resample(consumer_loan,\n",
    "                              replace=False,\n",
    "                              n_samples=600,\n",
    "                              random_state=42)\n",
    "\n",
    "debt_collection_downsample = resample(debt_collection,\n",
    "                              replace=False,\n",
    "                              n_samples=600,\n",
    "                              random_state=42)\n",
    "\n",
    "credit_reporting_downsample = resample(credit_reporting,\n",
    "                              replace=False,\n",
    "                              n_samples=600,\n",
    "                              random_state=42)\n",
    "\n",
    "student_loan_downsample = resample(student_loan,\n",
    "                              replace=False,\n",
    "                              n_samples=500,\n",
    "                              random_state=42)\n",
    "\n",
    "bank_account_downsample = resample(bank_account,\n",
    "                              replace=False,\n",
    "                              n_samples=600,\n",
    "                              random_state=42)\n",
    "\n",
    "money_transfers_downsample = resample(money_transfers,\n",
    "                              replace=False,\n",
    "                              n_samples=160,\n",
    "                              random_state=42)\n",
    "\n",
    "payday_loan_downsample = resample(payday_loan,\n",
    "                              replace=False,\n",
    "                              n_samples=80,\n",
    "                              random_state=42)\n",
    "\n",
    "prepaid_card_downsample = resample(prepaid_card,\n",
    "                              replace=False,\n",
    "                              n_samples=130,\n",
    "                              random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T12:25:19.532935Z",
     "iopub.status.busy": "2023-06-02T12:25:19.532127Z",
     "iopub.status.idle": "2023-06-02T12:25:19.540155Z",
     "shell.execute_reply": "2023-06-02T12:25:19.539098Z",
     "shell.execute_reply.started": "2023-06-02T12:25:19.532895Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.concat([mortgage_downsample, credit_card_downsample, consumer_loan_downsample, debt_collection_downsample, credit_reporting_downsample, student_loan_downsample, bank_account_downsample, money_transfers_downsample, payday_loan_downsample, prepaid_card_downsample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T12:25:26.741105Z",
     "iopub.status.busy": "2023-06-02T12:25:26.740699Z",
     "iopub.status.idle": "2023-06-02T12:25:26.751476Z",
     "shell.execute_reply": "2023-06-02T12:25:26.750276Z",
     "shell.execute_reply.started": "2023-06-02T12:25:26.741075Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mortgage                   600\n",
       "Credit card                600\n",
       "Consumer Loan              600\n",
       "Debt collection            600\n",
       "Credit reporting           600\n",
       "Bank account or service    600\n",
       "Student loan               500\n",
       "Money transfers            160\n",
       "Prepaid card               130\n",
       "Payday loan                 80\n",
       "Name: product, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"product\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T12:25:34.245345Z",
     "iopub.status.busy": "2023-06-02T12:25:34.244926Z",
     "iopub.status.idle": "2023-06-02T12:25:34.252812Z",
     "shell.execute_reply": "2023-06-02T12:25:34.251481Z",
     "shell.execute_reply.started": "2023-06-02T12:25:34.245316Z"
    }
   },
   "outputs": [],
   "source": [
    "test = data.loc[~data.index.isin(train.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T12:25:41.451378Z",
     "iopub.status.busy": "2023-06-02T12:25:41.450950Z",
     "iopub.status.idle": "2023-06-02T12:25:41.463231Z",
     "shell.execute_reply": "2023-06-02T12:25:41.462315Z",
     "shell.execute_reply.started": "2023-06-02T12:25:41.451346Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mortgage                   5442\n",
       "Debt collection            2232\n",
       "Credit card                1693\n",
       "Bank account or service    1330\n",
       "Credit reporting           1153\n",
       "Consumer Loan               466\n",
       "Student loan                234\n",
       "Money transfers              41\n",
       "Prepaid card                 30\n",
       "Payday loan                  20\n",
       "Name: product, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[\"product\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-02T12:25:49.535050Z",
     "iopub.status.busy": "2023-06-02T12:25:49.534617Z",
     "iopub.status.idle": "2023-06-02T12:25:49.542420Z",
     "shell.execute_reply": "2023-06-02T12:25:49.541421Z",
     "shell.execute_reply.started": "2023-06-02T12:25:49.534999Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce GTX 1070\n"
     ]
    }
   ],
   "source": [
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>consumer_complaint_narrative</th>\n",
       "      <th>genre_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>289175</th>\n",
       "      <td>Mortgage</td>\n",
       "      <td>we have been trying to get our home out of for...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255512</th>\n",
       "      <td>Mortgage</td>\n",
       "      <td>carrington mortgage took over servicing my loa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504921</th>\n",
       "      <td>Mortgage</td>\n",
       "      <td>this is a dispute to case number . i received ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297108</th>\n",
       "      <td>Mortgage</td>\n",
       "      <td>is   to any ? dear .... my name is  ,    with ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312177</th>\n",
       "      <td>Mortgage</td>\n",
       "      <td>,  i took out a mortgage . less than a month ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224279</th>\n",
       "      <td>Prepaid card</td>\n",
       "      <td>i signed up for pay power  visa card to get a ...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245873</th>\n",
       "      <td>Prepaid card</td>\n",
       "      <td>i purchased  goggle . gift cards and when i we...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297169</th>\n",
       "      <td>Prepaid card</td>\n",
       "      <td>on  , i was online trying to file for identity...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519629</th>\n",
       "      <td>Prepaid card</td>\n",
       "      <td>on   i noticed some suspicious activity on my ...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517741</th>\n",
       "      <td>Prepaid card</td>\n",
       "      <td>on saturday,  , at exactly  pacific time i was...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4470 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             product                       consumer_complaint_narrative  \\\n",
       "289175      Mortgage  we have been trying to get our home out of for...   \n",
       "255512      Mortgage  carrington mortgage took over servicing my loa...   \n",
       "504921      Mortgage  this is a dispute to case number . i received ...   \n",
       "297108      Mortgage  is   to any ? dear .... my name is  ,    with ...   \n",
       "312177      Mortgage   ,  i took out a mortgage . less than a month ...   \n",
       "...              ...                                                ...   \n",
       "224279  Prepaid card  i signed up for pay power  visa card to get a ...   \n",
       "245873  Prepaid card  i purchased  goggle . gift cards and when i we...   \n",
       "297169  Prepaid card  on  , i was online trying to file for identity...   \n",
       "519629  Prepaid card  on   i noticed some suspicious activity on my ...   \n",
       "517741  Prepaid card  on saturday,  , at exactly  pacific time i was...   \n",
       "\n",
       "        genre_id  \n",
       "289175         0  \n",
       "255512         0  \n",
       "504921         0  \n",
       "297108         0  \n",
       "312177         0  \n",
       "...          ...  \n",
       "224279         9  \n",
       "245873         9  \n",
       "297169         9  \n",
       "519629         9  \n",
       "517741         9  \n",
       "\n",
       "[4470 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we are going use Test rank to summarize all the consumer_complaint_narrative that is more than 512 tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pytextrank\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.add_pipe(\"textrank\")\n",
    "def summarize(input_text: str, max_tokens: int = 512):\n",
    "    # Load a SpaCy model. For example, the English model.\n",
    "\n",
    "\n",
    "    # Parse the document with SpaCy.\n",
    "    doc = nlp(input_text)\n",
    "\n",
    "    # If the text is less than 512 words, return the original text.\n",
    "    if len(doc) <= max_tokens:\n",
    "        return input_text\n",
    "\n",
    "    # Extract the phrases using TextRank.\n",
    "    phrases = \", \".join([p.text for p in doc._.phrases])\n",
    "\n",
    "    summarized_doc = []  # Initialize an empty list to store the summarized sentences\n",
    "\n",
    "    # Iterate over the sentences generated by textrank.summary and append them to the list\n",
    "    for sent in doc._.textrank.summary(limit_sentences=50):\n",
    "        summarized_doc.append(sent)\n",
    "\n",
    "\n",
    "    # Join the sentences to form the summary.\n",
    "    summary = \" \".join([span.text for span in summarized_doc])\n",
    "\n",
    "    # If the summary is longer than max_tokens, truncate it.\n",
    "    if len(summary.split()) > max_tokens:\n",
    "        summary = \" \".join(summary.split()[:max_tokens])\n",
    "\n",
    "    return summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------before TextRank---------------------\n",
      "\n",
      "is   to any ? dear .... my name is  ,    with residence at    ,  fl . this is my  time trying to have an answer about in my opinion is a force of power, not a justice. here is my history and i look for answer, positive or negative but an answer that convince me that i am wrong. i own the deed of my house but with a lien for a mortgage loan. i stared a loan modification with the loan servicer on    with a  trial payments,    and      , after a  payment was made, i received a loan modification agreement. the agreement says on section  lt acknowledgements and preconditions to modification. i understand and acknowledge that a. time is of the essence under this agreement b. if prior to the modification effective date as set forth in section  the servicer determines that my representations in section  are no longer true and correct, the loan documents will not be modified and this agreement will terminate. in this event, the servicer will have all of the rights and remedies provide by the loan documents andc. i understand that the loan documents will not be modified unless and until i i received from the servicer a copy of this agreement signed by the servicer, and   the modification effective date as defined in section  has occurred. i further understand and agree that the servicer will not be obligated or bound to make any modification of the loan documents if i fail to meet any one of the requirements under this agreement. section . the modification. if my representations in section  continue to be true in all material respects and all preconditions to the modification set forth in section  have been met, the loan documents will automatically become modified    the modification effective date and all unpaid late charges that remain unpaid will be waived. the loan documents will be modified and the first modified payment will be due on    gt   , when i tried to make the mortgage payment as stipulated on the loan agreement, the servicer told me that they can not accept the payment because the loan modification was n t complete yet and the same happen   . after been talking with the relationship manager about it, he says the same, the loan modification was n t complete but i never received a letter from the servicer explaining that they are behind in the process but the loan modification is approved until    or , i do n t exactly remember, when i spoke with the relationship manager and he told me that everything is approved    few days after, i received a loan statement showing month behind, date   . when i call, they said that i suppose to make the payments for  and , i claim that i was n t allow because the modification process was late but they ask me to make those month payments if i would like to have my mortgage up to date, and if not it will be behind those month. i received the executed modification agreement the first or second week of   , and it was signed by the servicer   . i write a complaint to the office of the loan consumer ombudsman and the answer i get was shocking me, she said regardless what the contract said your  and  payments are behind. as i mention before, i tried to many time to have an explanation from different source about this and i found that is the force of power . i do n t have the money to employee an attorney who will be charging me . or more per hour where could be ended around hours equal . when i was n t the party who was late in the process as it recognized by  , consumer account analyst from the office of the consumer ombudsman at ocwen loan servicing in a \n",
      "\n",
      "-----------------------Progressing---------------------\n",
      "\n",
      "i stared a loan modification with the loan servicer on with a trial payments, and , after a payment was made, i received a loan modification agreement. when i was n t the party who was late in the process as it recognized by , consumer account analyst from the office of the consumer ombudsman at ocwen loan servicing in a after been talking with the relationship manager about it, he says the same, the loan modification was n t complete but i never received a letter from the servicer explaining that they are behind in the process but the loan modification is approved until or , i do n t exactly remember, when i spoke with the relationship manager and he told me that everything is approved few days after, i received a loan statement showing month behind, date . the loan documents will be modified and the first modified payment will be due on gt , when i tried to make the mortgage payment as stipulated on the loan agreement, the servicer told me that they can not accept the payment because the loan modification was n t complete yet and the same happen . the agreement says on section lt acknowledgements and preconditions to modification. when i call, they said that i suppose to make the payments for and , i claim that i was n t allow because the modification process was late but they ask me to make those month payments if i would like to have my mortgage up to date, and if not it will be behind those month. if prior to the modification effective date as set forth in section the servicer determines that my representations in section are no longer true and correct, the loan documents will not be modified and this agreement will terminate. i understand that the loan documents will not be modified unless and until i i received from the servicer a copy of this agreement signed by the servicer, and the modification effective date as defined in section has occurred. section . if my representations in section continue to be true in all material respects and all preconditions to the modification set forth in section have been met, the loan documents will automatically become modified the modification effective date and all unpaid late charges that remain unpaid will be waived. i do n t have the money to employee an attorney who will be charging me . is to any ? dear .... my name is , with residence at , fl . this is my time trying to have an answer about in my opinion is a force of power, not a justice. here is my history and i look for answer, positive or negative but an answer that convince me that i am wrong. i own the deed of my house but with a lien for a mortgage loan. i understand and acknowledge that a. time is of the essence under this agreement b. in this event, the servicer will have all of the rights and remedies\n",
      "\n",
      "-----------------------after TextRank---------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17880/1645436624.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[\"consumer_complaint_narrative\"] = test[\"consumer_complaint_narrative\"].apply(summarize)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n-----------------------before TextRank---------------------\\n\")\n",
    "\n",
    "\n",
    "print(train[\"consumer_complaint_narrative\"][297108])\n",
    "print(\"\\n-----------------------Progressing---------------------\\n\")\n",
    "try:\n",
    "    train[\"consumer_complaint_narrative\"] = train[\"consumer_complaint_narrative\"].apply(summarize)\n",
    "    test[\"consumer_complaint_narrative\"] = test[\"consumer_complaint_narrative\"].apply(summarize)\n",
    "except Exception as e:\n",
    "    print(\"An error occurred while applying text_rank:\", str(e))\n",
    "    \n",
    "print(train[\"consumer_complaint_narrative\"][297108])\n",
    "print(\"\\n-----------------------after TextRank---------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we couldtrain the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_summary = train.consumer_complaint_narrative.values\n",
    "train_labels = train.genre_id.values\n",
    "\n",
    "test_summary = test.consumer_complaint_narrative.values\n",
    "test_labels = test.genre_id.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM, BertTokenizer,RobertaTokenizer\n",
    "\n",
    "# Create a tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "\n",
    "# Tokenize the text\n",
    "def tokenize_text(summary, max_length=512):\n",
    "    # Tokenize the 'summary' column of the DataFrame using the tokenizer's batch_encode_plus method\n",
    "    # df['summary'].tolist() converts the 'summary' column into a list of strings\n",
    "    # max_length specifies the maximum length of the tokenized sequences\n",
    "    # padding='max_length' pads the tokenized sequences to have a length of max_length\n",
    "    # truncation=True truncates the tokenized sequences if they exceed the max_length\n",
    "    return tokenizer.batch_encode_plus(\n",
    "        summary.tolist(), \n",
    "        max_length=max_length, \n",
    "        padding='max_length', \n",
    "        truncation=True\n",
    "    )\n",
    "\n",
    "tokenized_train_texts = tokenize_text(train_summary)\n",
    "tokenized_test_texts = tokenize_text(test_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Then prepare the dataset and dataloader\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class BookDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# Create the dataset\n",
    "train_dataset = BookDataset(tokenized_train_texts, train['genre_id'].values)\n",
    "test_dataset = BookDataset(tokenized_test_texts, test['genre_id'].values)\n",
    "\n",
    "# Create the dataloader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, RobertaForSequenceClassification\n",
    "\n",
    "model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=len(train['genre_id'].unique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                        | 0/1118 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 7.92 GiB total capacity; 6.54 GiB already allocated; 27.50 MiB free; 6.59 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 36\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm(train_dataloader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     34\u001b[0m     batch \u001b[38;5;241m=\u001b[39m {k: v\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m---> 36\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m     loss \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mloss\n\u001b[1;32m     38\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/miniconda3/envs/textsum/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/textsum/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py:1216\u001b[0m, in \u001b[0;36mRobertaForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1208\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1209\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1210\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1211\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1212\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1213\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1214\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1216\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroberta\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1217\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1227\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1228\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(sequence_output)\n",
      "File \u001b[0;32m~/miniconda3/envs/textsum/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/textsum/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py:852\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    843\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    845\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m    846\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m    847\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    850\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[1;32m    851\u001b[0m )\n\u001b[0;32m--> 852\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    864\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    865\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/textsum/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/textsum/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py:527\u001b[0m, in \u001b[0;36mRobertaEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    518\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[1;32m    519\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m    520\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    524\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    525\u001b[0m     )\n\u001b[1;32m    526\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 527\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    534\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    537\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/miniconda3/envs/textsum/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/textsum/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py:411\u001b[0m, in \u001b[0;36mRobertaLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    401\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    408\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    409\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    410\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 411\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    418\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    420\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/textsum/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/textsum/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py:338\u001b[0m, in \u001b[0;36mRobertaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    330\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    336\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    337\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m--> 338\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[1;32m    348\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/textsum/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/textsum/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py:268\u001b[0m, in \u001b[0;36mRobertaSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    264\u001b[0m attention_probs \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39msoftmax(attention_scores, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# This is actually dropping out entire tokens to attend to, which might\u001b[39;00m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;66;03m# seem a bit unusual, but is taken from the original Transformer paper.\u001b[39;00m\n\u001b[0;32m--> 268\u001b[0m attention_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_probs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;66;03m# Mask heads if we want to\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m head_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/textsum/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/textsum/lib/python3.9/site-packages/torch/nn/modules/dropout.py:59\u001b[0m, in \u001b[0;36mDropout.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/textsum/lib/python3.9/site-packages/torch/nn/functional.py:1252\u001b[0m, in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1.0\u001b[39m:\n\u001b[1;32m   1251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout probability has to be between 0 and 1, \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(p))\n\u001b[0;32m-> 1252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _VF\u001b[38;5;241m.\u001b[39mdropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 7.92 GiB total capacity; 6.54 GiB already allocated; 27.50 MiB free; 6.59 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import torch\n",
    "\n",
    "# Initialize the optimizer\n",
    "optimizer = Adam(model.parameters(), lr=2e-5)\n",
    "\n",
    "# Move the model to the GPU\n",
    "model.train()\n",
    "model.to('cuda')\n",
    "\n",
    "# Initialize a list to store the loss values\n",
    "losses = []\n",
    "\n",
    "checkpoint_path = \"Model_RoBERTa_ds2_no_textrank.pth\"  # Change to your preferred location\n",
    "\n",
    "start_epoch = 0\n",
    "\n",
    "# Load from checkpoint if it exists\n",
    "if os.path.exists(checkpoint_path):\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    losses = checkpoint['losses']\n",
    "    print(\"Loaded checkpoint.\")\n",
    "\n",
    "# Training \n",
    "for epoch in range(start_epoch, 4):\n",
    "    print(f\"Starting epoch {epoch}\")\n",
    "    for batch in tqdm(train_dataloader, desc=\"Training\"):\n",
    "        batch = {k: v.to('cuda') for k, v in batch.items()}\n",
    "\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "\n",
    "        # Optimize the model parameters\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Append the loss value to the list\n",
    "        losses.append(loss.item())  \n",
    "\n",
    "    # Save checkpoint after each epoch\n",
    "    torch.save({\n",
    "        'epoch': epoch + 1,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'losses': losses,\n",
    "    }, checkpoint_path)\n",
    "    print(f\"Saved checkpoint for epoch {epoch}.\")\n",
    "\n",
    "    # Plot the loss values after each epoch\n",
    "    plt.plot(losses)\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss over Iterations')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the model\n",
    "checkpoint_path = \"model2_with_textrank.pth\"  # Change to your preferred location\n",
    "if os.path.exists(checkpoint_path):\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    losses = checkpoint['losses']\n",
    "    print(\"Loaded checkpoint.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Assuming your model is stored in a variable called 'model'\n",
    "# Move the model from GPU to CPU\n",
    "model = model.to(torch.device('cpu'))\n",
    "\n",
    "# Optionally, if you have multiple GPUs and want to free the memory on all of them, use:\n",
    "# model = model.to(torch.device('cpu')).cuda()\n",
    "\n",
    "# If you want to release the GPU memory completely, you can also use:\n",
    "# del model\n",
    "# torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model.to('cuda')\n",
    "predictions = []\n",
    "true_labels = []\n",
    "\n",
    "# Iterate over the test dataset\n",
    "for batch in test_dataloader:\n",
    "    batch = {k: v.to('cuda') for k, v in batch.items()}\n",
    "\n",
    "    # Disable gradient calculation\n",
    "    with torch.no_grad():\n",
    "        # Perform inference\n",
    "        outputs = model(**batch)\n",
    "        \n",
    "    predicted_values = outputs.logits\n",
    "    predictions.extend(predicted_values)\n",
    "    true_labels.extend(batch['labels'].tolist())\n",
    "\n",
    "# Convert logits to predictions\n",
    "predictions = [torch.argmax(item).item() for item in predictions]\n",
    "\n",
    "# Make sure that true_labels is a list\n",
    "assert isinstance(true_labels, list)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(true_labels, predictions)\n",
    "\n",
    "print(report)\n",
    "\n",
    "# Save the report to a file\n",
    "with open('Classreport_RoBERTa_ds2_no_textrank.txt', 'w') as file:\n",
    "    file.write(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
