{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import torch\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4657, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>title</th>\n",
       "      <th>genre</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Drowned Wednesday</td>\n",
       "      <td>fantasy</td>\n",
       "      <td>Drowned Wednesday is the first Trustee among ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The Lost Hero</td>\n",
       "      <td>fantasy</td>\n",
       "      <td>As the book opens, Jason awakens on a school ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>The Eyes of the Overworld</td>\n",
       "      <td>fantasy</td>\n",
       "      <td>Cugel is easily persuaded by the merchant Fia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Magic's Promise</td>\n",
       "      <td>fantasy</td>\n",
       "      <td>The book opens with Herald-Mage Vanyel return...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Taran Wanderer</td>\n",
       "      <td>fantasy</td>\n",
       "      <td>Taran and Gurgi have returned to Caer Dallben...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                      title    genre  \\\n",
       "0      0          Drowned Wednesday  fantasy   \n",
       "1      1              The Lost Hero  fantasy   \n",
       "2      2  The Eyes of the Overworld  fantasy   \n",
       "3      3            Magic's Promise  fantasy   \n",
       "4      4             Taran Wanderer  fantasy   \n",
       "\n",
       "                                             summary  \n",
       "0   Drowned Wednesday is the first Trustee among ...  \n",
       "1   As the book opens, Jason awakens on a school ...  \n",
       "2   Cugel is easily persuaded by the merchant Fia...  \n",
       "3   The book opens with Herald-Mage Vanyel return...  \n",
       "4   Taran and Gurgi have returned to Caer Dallben...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data.csv\")\n",
    "\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns = [\"index\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num labels:  10\n"
     ]
    }
   ],
   "source": [
    "num_labels = len(data.genre.unique())\n",
    "print(\"num labels: \", num_labels)\n",
    "genre2id = {genre: i for i, genre in enumerate(data.genre.unique())}\n",
    "id2genre = {i: genre for i, genre in enumerate(data.genre.unique())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub('[^a-zA-Z0-9\\.\\,\\?\\!]', ' ', str(text).lower()) # remove all except lowercase, uppercase, digits, punctuation\n",
    "    text = re.sub('\\[.*?\\]', '', text) # remove any text in square brackets\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text) # remove any links present \n",
    "    text = re.sub('\\n', ' ', text) # remove the next line character\n",
    "    text = re.sub('\\w*\\d\\w*', '', text) # remove the words contaitning numbers\n",
    "    text = re.sub('\\s+', ' ', text) # remove extra spaces\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>genre</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Drowned Wednesday</td>\n",
       "      <td>fantasy</td>\n",
       "      <td>drowned wednesday is the first trustee among ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Lost Hero</td>\n",
       "      <td>fantasy</td>\n",
       "      <td>as the book opens, jason awakens on a school ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Eyes of the Overworld</td>\n",
       "      <td>fantasy</td>\n",
       "      <td>cugel is easily persuaded by the merchant fia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Magic's Promise</td>\n",
       "      <td>fantasy</td>\n",
       "      <td>the book opens with herald mage vanyel return...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Taran Wanderer</td>\n",
       "      <td>fantasy</td>\n",
       "      <td>taran and gurgi have returned to caer dallben...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       title    genre  \\\n",
       "0          Drowned Wednesday  fantasy   \n",
       "1              The Lost Hero  fantasy   \n",
       "2  The Eyes of the Overworld  fantasy   \n",
       "3            Magic's Promise  fantasy   \n",
       "4             Taran Wanderer  fantasy   \n",
       "\n",
       "                                             summary  \n",
       "0   drowned wednesday is the first trustee among ...  \n",
       "1   as the book opens, jason awakens on a school ...  \n",
       "2   cugel is easily persuaded by the merchant fia...  \n",
       "3   the book opens with herald mage vanyel return...  \n",
       "4   taran and gurgi have returned to caer dallben...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"summary\"] = data[\"summary\"].apply(clean_text)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"genre_id\"] = data[\"genre\"].apply(lambda a: genre2id[a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "thriller      1023\n",
       "fantasy        876\n",
       "science        647\n",
       "history        600\n",
       "horror         600\n",
       "crime          500\n",
       "romance        111\n",
       "psychology     100\n",
       "sports         100\n",
       "travel         100\n",
       "Name: genre, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"genre\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "fantasy_summaries = data[data[\"genre_id\"] == 0]\n",
    "science_summaries = data[data[\"genre_id\"] == 1]\n",
    "crime_summaries = data[data[\"genre_id\"] == 2]\n",
    "history_summaries = data[data[\"genre_id\"] == 3]\n",
    "horror_summaries = data[data[\"genre_id\"] == 4]\n",
    "thriller_summaries = data[data[\"genre_id\"] == 5]\n",
    "psychology_summaries = data[data[\"genre_id\"] == 6]\n",
    "romance_summaries = data[data[\"genre_id\"] == 7]\n",
    "sports_summaries = data[data[\"genre_id\"] == 8]\n",
    "travel_summaries = data[data[\"genre_id\"] == 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "fantasy_downsample = resample(fantasy_summaries,\n",
    "                              replace=False,\n",
    "                              n_samples=300,\n",
    "                              random_state=42)\n",
    "\n",
    "science_downsample = resample(science_summaries,\n",
    "                              replace=False,\n",
    "                              n_samples=300,\n",
    "                              random_state=42)\n",
    "\n",
    "crime_downsample = resample(crime_summaries,\n",
    "                              replace=False,\n",
    "                              n_samples=300,\n",
    "                              random_state=42)\n",
    "\n",
    "history_downsample = resample(history_summaries,\n",
    "                              replace=False,\n",
    "                              n_samples=300,\n",
    "                              random_state=42)\n",
    "\n",
    "horror_downsample = resample(horror_summaries,\n",
    "                              replace=False,\n",
    "                              n_samples=300,\n",
    "                              random_state=42)\n",
    "\n",
    "thriller_downsample = resample(thriller_summaries,\n",
    "                              replace=False,\n",
    "                              n_samples=300,\n",
    "                              random_state=42)\n",
    "\n",
    "psychology_downsample = resample(psychology_summaries,\n",
    "                              replace=False,\n",
    "                              n_samples=80,\n",
    "                              random_state=42)\n",
    "\n",
    "romance_downsample = resample(romance_summaries,\n",
    "                              replace=False,\n",
    "                              n_samples=80,\n",
    "                              random_state=42)\n",
    "\n",
    "sports_downsample = resample(sports_summaries,\n",
    "                              replace=False,\n",
    "                              n_samples=80,\n",
    "                              random_state=42)\n",
    "\n",
    "travel_downsample = resample(travel_summaries,\n",
    "                              replace=False,\n",
    "                              n_samples=80,\n",
    "                              random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([fantasy_downsample, science_downsample, crime_downsample, history_downsample, horror_downsample, thriller_downsample, psychology_downsample, romance_downsample, sports_downsample, travel_downsample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fantasy       300\n",
       "science       300\n",
       "crime         300\n",
       "history       300\n",
       "horror        300\n",
       "thriller      300\n",
       "psychology     80\n",
       "romance        80\n",
       "sports         80\n",
       "travel         80\n",
       "Name: genre, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"genre\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = data.loc[~data.index.isin(train.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "thriller      723\n",
       "fantasy       576\n",
       "science       347\n",
       "history       300\n",
       "horror        300\n",
       "crime         200\n",
       "romance        31\n",
       "psychology     20\n",
       "sports         20\n",
       "travel         20\n",
       "Name: genre, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[\"genre\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce GTX 1070\n"
     ]
    }
   ],
   "source": [
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>genre</th>\n",
       "      <th>summary</th>\n",
       "      <th>genre_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>The Forest House</td>\n",
       "      <td>fantasy</td>\n",
       "      <td>in the early days of the conquest, when the r...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4436</th>\n",
       "      <td>Heartless</td>\n",
       "      <td>fantasy</td>\n",
       "      <td>long before she was the terror of wonderland t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4609</th>\n",
       "      <td>A Hat Full of Sky</td>\n",
       "      <td>fantasy</td>\n",
       "      <td>we see you. now we are you. no real witch woul...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4473</th>\n",
       "      <td>Going Postal</td>\n",
       "      <td>fantasy</td>\n",
       "      <td>arch swindler moist van lipwig never believed ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>Tithe : A Modern Faerie Tale</td>\n",
       "      <td>fantasy</td>\n",
       "      <td>tithe follows the story of sixteen year old a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             title    genre  \\\n",
       "365               The Forest House  fantasy   \n",
       "4436                     Heartless  fantasy   \n",
       "4609             A Hat Full of Sky  fantasy   \n",
       "4473                  Going Postal  fantasy   \n",
       "213   Tithe : A Modern Faerie Tale  fantasy   \n",
       "\n",
       "                                                summary  genre_id  \n",
       "365    in the early days of the conquest, when the r...         0  \n",
       "4436  long before she was the terror of wonderland t...         0  \n",
       "4609  we see you. now we are you. no real witch woul...         0  \n",
       "4473  arch swindler moist van lipwig never believed ...         0  \n",
       "213    tithe follows the story of sixteen year old a...         0  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By now, data has been cleaned. Next step is to tokenize, train, and test.\n",
    "The first step is to use TextRank from Gensim to rank the first few sentences, and then we will train on BERT and RoBERTA to see its' performance.\n",
    "\n",
    "# Text Rank by Spacy:\n",
    "Note that this could be skipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pytextrank\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.add_pipe(\"textrank\")\n",
    "def summarize(input_text: str, max_tokens: int = 512):\n",
    "    # Load a SpaCy model. For example, the English model.\n",
    "\n",
    "\n",
    "    # Parse the document with SpaCy.\n",
    "    doc = nlp(input_text)\n",
    "\n",
    "    # If the text is less than 512 words, return the original text.\n",
    "    if len(doc) <= max_tokens:\n",
    "        return input_text\n",
    "\n",
    "    # Extract the phrases using TextRank.\n",
    "    phrases = \", \".join([p.text for p in doc._.phrases])\n",
    "\n",
    "    summarized_doc = []  # Initialize an empty list to store the summarized sentences\n",
    "\n",
    "    # Iterate over the sentences generated by textrank.summary and append them to the list\n",
    "    for sent in doc._.textrank.summary(limit_sentences=50):\n",
    "        summarized_doc.append(sent)\n",
    "\n",
    "\n",
    "    # Join the sentences to form the summary.\n",
    "    summary = \" \".join([span.text for span in summarized_doc])\n",
    "\n",
    "    # If the summary is longer than max_tokens, truncate it.\n",
    "    if len(summary.split()) > max_tokens:\n",
    "        summary = \" \".join(summary.split()[:max_tokens])\n",
    "\n",
    "    return summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------------before TextRank---------------------\n",
      "\n",
      " tithe follows the story of sixteen year old american kaye fierch, a young nomad who tours the country with her mother s rock band. the book begins in philadelphia, at a gig her mother s band stepping razor is playing in a seedy bar in philadelphia. after her mother s boyfriend and guitarist, lloyd, attempts to stab her mother under the enchantment of nephamael a knight of the unseelie court her mother takes her back to kaye s grandmother s house in new jersey to stay. once at her grandmother s house, kaye begins to look for her old imaginary friends she had during her childhood, faeries named lutie loo, spike, and gristle. however, she fails to find them and, begins to suspect that they were simply figments of her imagination. her suspicions dissolve when she finds and saves the life of roiben, a faerie knight, by pulling an iron tipped arrow from his chest. in return, he grants her three truthfully answered questions about anything she chooses, which she does not immediately use. soon after this, spike and lutie loo contact her and warn her that roiben is a murderer who has killed gristle. as revenge, kaye tricks roiben into telling her his full name she later learns that faeries can be controlled by their true names . later on, her friends tell her that she is a changeling and that she should keep her human appearance, because the unseelie court wishes to use her as a tithe in order to bind the solitary fey to the court s queen, nicnevin. since kaye is not mortal, the ritual will be forfeit, and the fey whom the unseelie court wishes to bind will go free. kaye attempts to control her newfound abilities by enlisting the help of a kelpie to teach her how to use magic. she is soon kidnapped by a group of fairies, as planned and is taken to the unseelie court to go through the sacrificial ceremony. before the ceremony roiben takes her to be prepared, having a dress made for her and allowing her to stay with him the night, where they acknowledge their feelings for one another. at the climax of the ceremony, kaye uses roiben s name to order him to free her from her bonds before she is killed, resulting in a bloodbath between roiben and the court before they flee safely. in the process, he kills the queen of the unseelie court and many of her guards. kaye and roiben spend the day at kaye s home, and discover that strange events are affecting the mortal world. odd reports of mauling and kidnappings are reported on the news and roiben makes kaye understand that this is a result of the solitary fey being free for the next seven years. kaye receives a call from her friend janet, inviting her to come to a halloween rave held at the waterfront, she tries to persuade her not to go but fails. after a failed attempt to receive help from her imaginary faerie friends, roiben and kaye attend the rave. they are separated, and kaye successfully locates her friends, but briefly leaves them to apologize to janet s boyfriend for bewitching him earlier in the novel. however, she finds that the kelpie who lives near the waterfront has taken janet into the water to kill her. in the novel, it is suggested that janet went with him out of loneliness and a desire to get revenge on her boyfriend for going off with kaye. kaye follows but is too late and she manages to convince the kelpie to relinquish her body. roiben finds kaye mourning for her friend and gets her home. the next morning, she and roiben travel to the seelie court s camp some distance away to see if corny is there. they reach a dead end, but discover that the knight nephamael has proclaimed himself the king of the unseelie court. roiben is suspicious of the situation and thinks that it is a trap for kaye and him. later, roiben s suspicions are proved correct when they enter the unseelie court. nephamael, who had discovered roiben s true name from spike before killing him, uses it to take control over roiben. he orders him to seize kaye, but roiben uses trickery to let her get away. kaye then devises a plan to poison nephamael, while corny and roiben amuse him. she goes through with it however, before nephamael is dead, the seelie queen arrives, hoping to take over the court right after her arrival corny goes insane and stabs nephamael multiple times, ultimately killing him . roiben prevents the queen s takeover attempt by claiming the throne as his.\n",
      "\n",
      "-----------------------Progressing---------------------\n",
      "\n",
      "\n",
      "-----------------------after TextRank---------------------\n",
      "\n",
      "kaye then devises a plan to poison nephamael, while corny and roiben amuse him. roiben finds kaye mourning for her friend and gets her home. kaye and roiben spend the day at kaye s home, and discover that strange events are affecting the mortal world. odd reports of mauling and kidnappings are reported on the news and roiben makes kaye understand that this is a result of the solitary fey being free for the next seven years. after a failed attempt to receive help from her imaginary faerie friends, roiben and kaye attend the rave. roiben is suspicious of the situation and thinks that it is a trap for kaye and him. he orders him to seize kaye, but roiben uses trickery to let her get away. nephamael, who had discovered roiben s true name from spike before killing him, uses it to take control over roiben. the next morning, she and roiben travel to the seelie court s camp some distance away to see if corny is there. she goes through with it however, before nephamael is dead, the seelie queen arrives, hoping to take over the court right after her arrival corny goes insane and stabs nephamael multiple times, ultimately killing him . since kaye is not mortal, the ritual will be forfeit, and the fey whom the unseelie court wishes to bind will go free. her suspicions dissolve when she finds and saves the life of roiben, a faerie knight, by pulling an iron tipped arrow from his chest. at the climax of the ceremony, kaye uses roiben s name to order him to free her from her bonds before she is killed, resulting in a bloodbath between roiben and the court before they flee safely. roiben prevents the queen s takeover attempt by claiming the throne as his. after her mother s boyfriend and guitarist, lloyd, attempts to stab her mother under the enchantment of nephamael a knight of the unseelie court her mother takes her back to kaye s grandmother s house in new jersey to stay. they reach a dead end, but discover that the knight nephamael has proclaimed himself the king of the unseelie court. tithe follows the story of sixteen year old american kaye fierch, a young nomad who tours the country with her mother s rock band. once at her grandmother s house, kaye begins to look for her old imaginary friends she had during her childhood, faeries named lutie loo, spike, and gristle. kaye attempts to control her newfound abilities by enlisting the help of a kelpie to teach her how to use magic. kaye receives a call from her friend janet, inviting her to come to a halloween rave held at the waterfront, she tries to persuade her not to go but fails. they are separated, and kaye successfully locates her friends, but briefly leaves them to apologize to janet s boyfriend for bewitching him earlier in the novel. in the novel, it is suggested that janet went with him out of loneliness and a desire to get revenge on her\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19224/3322729074.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test[\"summary\"] = test[\"summary\"].apply(summarize)\n"
     ]
    }
   ],
   "source": [
    "train = pd.concat([fantasy_downsample, science_downsample, crime_downsample, history_downsample, horror_downsample, thriller_downsample, psychology_downsample, romance_downsample, sports_downsample, travel_downsample])\n",
    "print(\"\\n-----------------------before TextRank---------------------\\n\")\n",
    "print(train[\"summary\"][213])\n",
    "\n",
    "print(\"\\n-----------------------Progressing---------------------\\n\")\n",
    "try:\n",
    "    train[\"summary\"] = train[\"summary\"].apply(summarize)\n",
    "    test[\"summary\"] = test[\"summary\"].apply(summarize)\n",
    "except Exception as e:\n",
    "    print(\"An error occurred while applying text_rank:\", str(e))\n",
    "    \n",
    "print(\"\\n-----------------------after TextRank---------------------\\n\")\n",
    "print(train[\"summary\"][213])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_summary = train.summary.values\n",
    "train_labels = train.genre_id.values\n",
    "\n",
    "test_summary = test.summary.values\n",
    "test_labels = test.genre_id.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM, BertTokenizer\n",
    "\n",
    "# Create a tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "\n",
    "# Tokenize the text\n",
    "def tokenize_text(summary, max_length=512):\n",
    "    # Tokenize the 'summary' column of the DataFrame using the tokenizer's batch_encode_plus method\n",
    "    # df['summary'].tolist() converts the 'summary' column into a list of strings\n",
    "    # max_length specifies the maximum length of the tokenized sequences\n",
    "    # padding='max_length' pads the tokenized sequences to have a length of max_length\n",
    "    # truncation=True truncates the tokenized sequences if they exceed the max_length\n",
    "    return tokenizer.batch_encode_plus(\n",
    "        summary.tolist(), \n",
    "        max_length=max_length, \n",
    "        padding='max_length', \n",
    "        truncation=True\n",
    "    )\n",
    "\n",
    "tokenized_train_texts = tokenize_text(train_summary)\n",
    "tokenized_test_texts = tokenize_text(test_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Then prepare the dataset and dataloader\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class BookDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# Create the dataset\n",
    "train_dataset = BookDataset(tokenized_train_texts, train['genre_id'].values)\n",
    "test_dataset = BookDataset(tokenized_test_texts, test['genre_id'].values)\n",
    "\n",
    "# Create the dataloader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "tensor(1)\n",
      "{'input_ids': tensor([[  101,  4704,  2011,  ...,     0,     0,     0],\n",
      "        [  101,  1048,  6887,  ...,     0,     0,     0],\n",
      "        [  101,  1996,  5436,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  2096, 11496,  ...,     0,     0,     0],\n",
      "        [  101,  1999,  1996,  ...,     0,     0,     0],\n",
      "        [  101,  1996,  3117,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([4, 6, 1, 1, 4, 2, 5, 3])}\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(train['genre_id'].values)):\n",
    "    if (train['genre_id'].values[i]!=train_dataset[i]['labels']):\n",
    "        print('not equal')\n",
    "        \n",
    "\n",
    "print(train['genre_id'].values[500])\n",
    "print(train_dataset[500]['labels'])\n",
    "for batch in train_dataloader:\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the model and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(train['genre_id'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  29%|█████████▎                      | 77/265 [01:02<02:33,  1.23it/s]"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import torch\n",
    "\n",
    "# Initialize the optimizer\n",
    "optimizer = Adam(model.parameters(), lr=2e-5)\n",
    "\n",
    "# Move the model to the GPU\n",
    "model.train()\n",
    "model.to('cuda')\n",
    "\n",
    "# Initialize a list to store the loss values\n",
    "losses = []\n",
    "\n",
    "checkpoint_path = \"model1_no_textrank.pth\"  # Change to your preferred location\n",
    "\n",
    "start_epoch = 0\n",
    "\n",
    "# Load from checkpoint if it exists\n",
    "if os.path.exists(checkpoint_path):\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    losses = checkpoint['losses']\n",
    "    print(\"Loaded checkpoint.\")\n",
    "\n",
    "# Training \n",
    "for epoch in range(start_epoch, 4):\n",
    "    print(f\"Starting epoch {epoch}\")\n",
    "    for batch in tqdm(train_dataloader, desc=\"Training\"):\n",
    "        batch = {k: v.to('cuda') for k, v in batch.items()}\n",
    "\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "\n",
    "        # Optimize the model parameters\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Append the loss value to the list\n",
    "        losses.append(loss.item())  \n",
    "\n",
    "    # Save checkpoint after each epoch\n",
    "    torch.save({\n",
    "        'epoch': epoch + 1,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'losses': losses,\n",
    "    }, checkpoint_path)\n",
    "    print(f\"Saved checkpoint for epoch {epoch}.\")\n",
    "\n",
    "    # Plot the loss values after each epoch\n",
    "    plt.plot(losses)\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss over Iterations')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the model\n",
    "if os.path.exists(checkpoint_path):\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(checkpoint['model_sta\n",
    "                                     +te_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    losses = checkpoint['losses']\n",
    "    print(\"Loaded checkpoint.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model now been trained, now evaluate the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model.to('cuda')\n",
    "predictions = []\n",
    "true_labels = []\n",
    "\n",
    "# Iterate over the test dataset\n",
    "for batch in test_dataloader:\n",
    "    batch = {k: v.to('cuda') for k, v in batch.items()}\n",
    "\n",
    "    # Disable gradient calculation\n",
    "    with torch.no_grad():\n",
    "        # Perform inference\n",
    "        outputs = model(**batch)\n",
    "        \n",
    "    predicted_values = outputs.logits\n",
    "    predictions.extend(predicted_values)\n",
    "    true_labels.extend(batch['labels'].tolist())\n",
    "\n",
    "# Convert logits to predictions\n",
    "predictions = [torch.argmax(item).item() for item in predictions]\n",
    "\n",
    "# Make sure that true_labels is a list\n",
    "assert isinstance(true_labels, list)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(true_labels, predictions)\n",
    "\n",
    "print(report)\n",
    "\n",
    "# Save the report to a file\n",
    "with open('classification_report_for_model1_no_textrank.txt', 'w') as file:\n",
    "    file.write(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Archive\n",
    "\n",
    "\n",
    "'''\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from gensim.summarization import summarize\n",
    "def text_rank(text,num):\n",
    "    \"\"\"\n",
    "    Apply TextRank algorithm to summarize the given text.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text to be summarized.\n",
    "        num (int): The desired number of sentences in the summary.\n",
    "\n",
    "    Returns:\n",
    "        str: The summarized text.\n",
    "\n",
    "    \"\"\"\n",
    "    # Split the text into sentences\n",
    "    sentences = sent_tokenize(text)\n",
    "    \n",
    "    # If the text has no sentences, return an empty string\n",
    "    if len(sentences) == 0:\n",
    "        return ''\n",
    "    \n",
    "    # If the text has less than four sentences, return the original text\n",
    "    if len(sentences) < num:\n",
    "        return text\n",
    "    \n",
    "    summary = summarize(text, ratio=0.3)\n",
    "    \n",
    "    # Split the summary into sentences\n",
    "    summary_sentences = summary.split('\\n')\n",
    "    \n",
    "    # If the summary has no sentences, return an empty string\n",
    "    if len(summary_sentences) == 0:\n",
    "        return ''\n",
    "    \n",
    "    # Otherwise, return the first four sentences of the summary\n",
    "    return ' '.join(summary_sentences[:num])\n",
    "\n",
    "#Now we keep the first few sentences for each summary.\n",
    "\n",
    "print(\"\\n-----------------------before TextRank---------------------\\n\")\n",
    "print(train[\"summary\"][575])\n",
    "\n",
    "print(\"\\n-----------------------Progressing---------------------\\n\")\n",
    "try:\n",
    "    train[\"summary\"] = train[\"summary\"].apply(lambda x: text_rank(x, num=4))\n",
    "except Exception as e:\n",
    "    print(\"An error occurred while applying text_rank:\", str(e))\n",
    "\n",
    "    \n",
    "print(\"\\n-----------------------after TextRank---------------------\\n\")\n",
    "print(train[\"summary\"][575])\n",
    "'''\n",
    "\n",
    "\n",
    "'''\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_df = train\n",
    "test_df = test\n",
    "\n",
    "class TextClassificationDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        text = str(self.texts[item])\n",
    "        label = self.labels[item]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            pad_to_max_length=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'text': text,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Preprocessing\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Create Datasets\n",
    "max_len = 64\n",
    "batch_size = 4\n",
    "train_dataset = TextClassificationDataset(\n",
    "    texts=train_df.summary.to_numpy(),\n",
    "    labels=train_df.genre_id.to_numpy(),\n",
    "    tokenizer=tokenizer,\n",
    "    max_len=max_len\n",
    ")\n",
    "test_dataset = TextClassificationDataset(\n",
    "    texts=test_df.summary.to_numpy(),\n",
    "    labels=test_df.genre_id.to_numpy(),\n",
    "    tokenizer=tokenizer,\n",
    "    max_len=max_len\n",
    ")\n",
    "\n",
    "# Create Dataloaders\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "num_labels = train_df['genre_id'].nunique()\n",
    "\n",
    "# Model and Optimizer\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_labels)\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "\n",
    "# Training\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "losses = []\n",
    "epochs = 3\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for batch in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs[0]\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Plot loss\n",
    "plt.plot(losses)\n",
    "plt.title('Training loss')\n",
    "plt.xlabel('Batch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "# Define the loss function\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Move the model to the GPU\n",
    "model.to('cuda')\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(5):\n",
    "    model.train()\n",
    "    for batch in train_dataloader:\n",
    "        batch = {k: v.to('cuda') for k, v in batch.items()}\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Evaluation loop\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_correct = 0\n",
    "        total_examples = 0\n",
    "        for batch in test_dataloader:\n",
    "            batch = {k: v.to('cuda') for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            predictions = torch.argmax(outputs.logits, dim=1)\n",
    "            labels = batch['labels']\n",
    "            total_correct += (predictions == labels).sum().item()\n",
    "            total_examples += len(labels)\n",
    "\n",
    "        accuracy = total_correct / total_examples\n",
    "        print(f\"Epoch {epoch + 1} - Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "'''\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class BertDataset(Dataset):\n",
    "    def __init__(self, summary, targets, tokenizer, max_len):\n",
    "        self.summary = summary\n",
    "        self.targets = targets\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.summary)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        summary = str(self.summary[item])\n",
    "        target = self.targets[item]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "          summary,\n",
    "          add_special_tokens=True,\n",
    "          max_length=self.max_len,\n",
    "          return_token_type_ids=False,\n",
    "          padding='max_length',\n",
    "          return_attention_mask=True,\n",
    "          return_tensors='pt',\n",
    "          truncation=True\n",
    "        )\n",
    "\n",
    "        return {\n",
    "          'summary_text': summary,\n",
    "          'input_ids': encoding['input_ids'].flatten(),\n",
    "          'attention_mask': encoding['attention_mask'].flatten(),\n",
    "          'targets': torch.tensor(target, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "    \n",
    "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
    "    ds = BertDataset(\n",
    "        summary=df.summary.to_numpy(),\n",
    "        targets=df.genre_id.to_numpy(),\n",
    "        tokenizer=tokenizer,\n",
    "        max_len=max_len\n",
    "    )\n",
    "\n",
    "    return DataLoader(\n",
    "        ds,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=4\n",
    "    )\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "textsum",
   "language": "python",
   "name": "textsum"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
